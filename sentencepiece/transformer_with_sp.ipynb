{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I referred to [the webpage](https://qiita.com/halhorn/items/c91497522be27bde17ce) for the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Activation, Layer, Embedding, Input\n",
    "from keras import backend as K\n",
    "from keras.initializers import RandomNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttention(Model):\n",
    "    ## hidden_dim has to be multiples of head_num\n",
    "    def __init__(self, hidden_dim=512, head_num=8, dropout_rate=0.1, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.head_num = head_num\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        self.q_dense_layer = Dense(hidden_dim, use_bias=False, name=\"q_dense_layer\")\n",
    "        self.k_dense_layer = Dense(hidden_dim, use_bias=False, name=\"k_dense_layer\")\n",
    "        self.v_dense_layer = Dense(hidden_dim, use_bias=False, name=\"v_dense_layer\")\n",
    "        self.output_dense_layer = Dense(hidden_dim, use_bias=False, name=\"output_dense_layer\")\n",
    "        self.attention_dropout_layer = Dropout(dropout_rate, name=\"attention_dropout_layer\")\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        print(\"split_heads inputs\", x)\n",
    "        batch_size, max_len, hidden_dim = tf.unstack(tf.shape(x))\n",
    "        #max_len, hidden_dim = tf.unstack(tf.shape(x))\n",
    "        x = tf.reshape(x, [batch_size, max_len, self.head_num, self.hidden_dim // self.head_num])\n",
    "        return tf.transpose(x, [0, 2, 1, 3])\n",
    "    \n",
    "    def combine_heads(self, heads):\n",
    "        batch_size, _, max_len, _ = tf.unstack(tf.shape(heads))\n",
    "        heads = tf.transpose(heads, [0, 2, 1, 3])\n",
    "        return tf.reshape(heads, [batch_size, max_len, self.hidden_dim])\n",
    "        \n",
    "    def call(self, query, memory):\n",
    "        #two arguments of query and memory are already encoded as embedded vectors for all words\n",
    "        q = self.q_dense_layer(query)\n",
    "        print(\"q\", q)\n",
    "        k = self.k_dense_layer(memory)\n",
    "        v = self.v_dense_layer(memory)\n",
    "        \n",
    "        q = self.split_heads(q)\n",
    "        k = self.split_heads(k)\n",
    "        v = self.split_heads(v)\n",
    "        \n",
    "        #for scaled dot-product\n",
    "        depth_inside_each_head = self.hidden_dim // self.head_num\n",
    "        q *= depth_inside_each_head ** -0.5\n",
    "        \n",
    "        score = tf.matmul(q, k, transpose_b=True)\n",
    "        normalized_score = Activation(\"softmax\")(score, name=\"attention_weight\")\n",
    "        normalized_score = self.attention_dropout_layer(normalized_score)\n",
    "        attention_weighted_output = tf.matmul(normalized_score, v)\n",
    "        attention_weighted_output = self.combine_head(attention_weighted_output)\n",
    "        return self.output_dense_layer(attention_weighted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SlefAttention class inherits MultiheadAttention class so that it can make query and memory come from the same source.\n",
    "class SelfAttention(MultiheadAttention):\n",
    "    \n",
    "    def call(self, query,):\n",
    "        return super().call(query, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForwardNetwork(Model):\n",
    "    \n",
    "    def __init__(self, hidden_dim, dropout_rate, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        self.first_dense_layer = Dense(hidden_dim*4, use_bias=True, activation=\"relu\", name=\"first_dense_layer\")\n",
    "        self.second_dense_layer = Dense(hidden_dim, use_bias=True, activation=\"linear\", name=\"second_dense_layer\")\n",
    "        self.dropout_layer = Dropout(dropout_rate, name=\"PFFN_dropout\")\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # make the network more flexible to learn for the first dense layer(non-linear transformation is used),\n",
    "        # and put the network back into the same hidden dim as original(linear transformation is used)\n",
    "        x = self.first_dense_layer(inputs)\n",
    "        x = self.dropout_layer(x)\n",
    "        return self.second_dense_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(Layer):\n",
    "    def build(self, input_shape):\n",
    "        print(\"input shape\", input_shape)\n",
    "        hidden_dim = 512\n",
    "        print(\"hidden dim:\", hidden_dim)\n",
    "        self.scale = self.add_weight(\"layer_norm_scale\", shape=[hidden_dim],\n",
    "                                    initializer=\"ones\")\n",
    "        self.shift = self.add_weight(\"layer_norm_shift\", shape=[hidden_dim],\n",
    "                                    initializer=\"zeros\")\n",
    "        super().build(input_shape)\n",
    "        \n",
    "    def call(self, inputs, epsilon=1e-6):\n",
    "        print(\"inside of layer norm inputs\", inputs)\n",
    "        mean = K.mean(inputs, axis=[-1], keepdims=True)\n",
    "        variance = K.var(inputs, axis=[-1], keepdims=True)\n",
    "        normalized_inputs = (inputs - mean) / (K.sqrt(variance) + epsilon)\n",
    "        print(\"normalized inputs\", normalized_inputs)\n",
    "        return normalized_inputs * self.scale + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreLayerNormPostResidualConnectionWrapper(Model):\n",
    "    def __init__(self, layer, dropout_rate, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.layer = layer\n",
    "        self.layer_norm = LayerNormalization()\n",
    "        self.dropout_layer = Dropout(dropout_rate)\n",
    "        \n",
    "    def call(self, inputs, *args, **kwargs):\n",
    "        print(\"pre layer norm starts\")\n",
    "        print(\"inside of prepos inputs\", inputs)\n",
    "        x = self.layer_norm(inputs)\n",
    "        x = self.layer(x, *args, **kwargs)\n",
    "        output = self.dropout_layer(x)\n",
    "        return inputs + output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddPositionalEncoding(Layer):\n",
    "    def call(self, inputs):\n",
    "        data_type = inputs.dtype\n",
    "        batch_size, max_len, emb_dim = tf.unstack(tf.shape(inputs))\n",
    "        # i is from 0 to 255 when emb_dim is 512\n",
    "        #so the doubled_i is from 0 to 510\n",
    "        doubled_i = K.arange(emb_dim) // 2 * 2\n",
    "        exponent = K.tile(K.expand_dims(doubled_i, 0), [max_len, 1])\n",
    "        denominator_matrix = K.pow(10000.0, K.cast(exponent / emb_dim, data_type))\n",
    "        \n",
    "        # since cos(x) = sin(x + Ï€/2), we convert the series of [sin, cos, sin, cos, ...]\n",
    "        # into [sin, sin, sin, sin, ...]\n",
    "        to_convert = K.cast(K.arange(emb_dim) % 2, data_type) * math.pi / 2\n",
    "        convert_matrix = K.tile(tf.expand_dims(to_convert, 0), [max_len, 1])\n",
    "        \n",
    "        seq_pos = K.arange(max_len)\n",
    "        numerator_matrix = K.cast(K.tile(K.expand_dims(seq_pos, 1), [1, emb_dim]), data_type)\n",
    "        \n",
    "        positinal_encoding = K.sin(numerator_matrix / denominator_matrix + convert_matrix)\n",
    "        batched_positional_encoding = K.tile(K.expand_dims(positinal_encoding, 0), [batch_size, 1, 1])\n",
    "        return inputs + batched_positional_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_ID = 0\n",
    "\n",
    "class TokenEmbedding(Layer):\n",
    "    def __init__(self, vocab_size, emb_dim, data_type=\"float32\", *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.emb_dim = emb_dim\n",
    "        self.data_type = data_type\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.embedding_layer = Embedding(self.vocab_size,\n",
    "                                   self.emb_dim,\n",
    "                                   embeddings_initializer=RandomNormal(mean=0.0, stddev=self.emb_dim**-0.5)\n",
    "                                  )\n",
    "        super().build(input_shape)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        mask_for_pads = tf.to_float(tf.not_equal(inputs, PAD_ID))\n",
    "        embedding = self.embedding_layer(inputs)\n",
    "        pads_masked_embedding = embedding * tf.expand_dims(mask_for_pads, -1)\n",
    "        return pads_masked_embedding * (self.emb_dim ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(Model):\n",
    "    def __init__(self, vocab_size, stack_num, head_num, emb_dim, dropout_rate, max_len, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.stack_num = stack_num\n",
    "        self.head_num = head_num\n",
    "        self.emb_dim = emb_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        self.token_emb_layer = TokenEmbedding(vocab_size, emb_dim)\n",
    "        self.add_pos_enc_layer = AddPositionalEncoding()\n",
    "        self.input_dropout_layer = Dropout(dropout_rate)\n",
    "        \n",
    "        self.attention_block_list = []\n",
    "        for _ in range(stack_num):\n",
    "            self_attention_layer = SelfAttention(emb_dim, head_num, dropout_rate, name=\"self_attention_layer\")\n",
    "            pffn_layer = PositionwiseFeedForwardNetwork(emb_dim, dropout_rate, \"pffn_layer\")\n",
    "            self.attention_block_list.append([\n",
    "                PreLayerNormPostResidualConnectionWrapper(self_attention_layer, dropout_rate, name=\"prepos_self_attention_wrapper\"),\n",
    "                PreLayerNormPostResidualConnectionWrapper(pffn_layer, dropout_rate, name=\"prepos_pffn_wrapper\")\n",
    "            ])\n",
    "        self.output_layer_norm = LayerNormalization()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.token_emb_layer(inputs)\n",
    "        print(\"first x\", x)\n",
    "        x = self.add_pos_enc_layer(x)\n",
    "        print(\"second x\", x)\n",
    "        x = self.input_dropout_layer(x)\n",
    "        print(\"third x\", x)\n",
    "        \n",
    "        for i, set_of_layers_list in enumerate(self.attention_block_list):\n",
    "            self_attention_layer, pffn_layer = tuple(set_of_layers_list)\n",
    "            print(\"fourth x\", x)\n",
    "            x = self_attention_layer(x)\n",
    "            print(\"fifth x\", x)\n",
    "            x = pffn_layer(x)\n",
    "            \n",
    "        return self.output_layer_norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first x Tensor(\"encoder_17/token_embedding_17/mul_1:0\", shape=(?, 717, 512), dtype=float32)\n",
      "second x Tensor(\"encoder_17/add_positional_encoding_17/add_1:0\", shape=(?, 717, 512), dtype=float32)\n",
      "third x Tensor(\"encoder_17/dropout_209/cond/Merge:0\", shape=(?, 717, 512), dtype=float32)\n",
      "fourth x Tensor(\"encoder_17/dropout_209/cond/Merge:0\", shape=(?, 717, 512), dtype=float32)\n",
      "pre layer norm starts\n",
      "inside of prepos inputs Tensor(\"encoder_17/dropout_209/cond/Merge:0\", shape=(?, 717, 512), dtype=float32)\n",
      "input shape (None, 717)\n",
      "hidden dim: 512\n",
      "inside of layer norm inputs Tensor(\"encoder_17/dropout_209/cond/Merge:0\", shape=(?, 717, 512), dtype=float32)\n",
      "normalized inputs Tensor(\"encoder_17/prepos_self_attention_wrapper/layer_normalization_209/truediv:0\", shape=(?, 717, 512), dtype=float32)\n",
      "q Tensor(\"encoder_17/prepos_self_attention_wrapper/self_attention_layer/q_dense_layer/Reshape_2:0\", shape=(?, 512), dtype=float32)\n",
      "split_heads inputs Tensor(\"encoder_17/prepos_self_attention_wrapper/self_attention_layer/q_dense_layer/Reshape_2:0\", shape=(?, 512), dtype=float32)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-632e85a9e65e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_LEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtransformer_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_LEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mencoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0msummarized_vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_LEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-a596af8e4b7e>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mself_attention_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpffn_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_of_layers_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fourth x\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fifth x\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpffn_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-b5d8166bea8b>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inside of prepos inputs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-21cca14ed881>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-56-789b1d6faecb>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, query, memory)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_dense_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-789b1d6faecb>\u001b[0m in \u001b[0;36msplit_heads\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#batch_size, max_len, hidden_dim = tf.unstack(tf.shape(x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": [
    "# Transformer classification model\n",
    "MAX_LEN = 717\n",
    "\n",
    "inputs = Input(shape=(MAX_LEN,))\n",
    "transformer_encoder = Encoder(vocab_size=8000, stack_num=6, head_num=8, emb_dim=512, dropout_rate=0.1, max_len=MAX_LEN)\n",
    "encoder_output = transformer_encoder(inputs)\n",
    "summarized_vecs = encoder_output[:, 0, :]\n",
    "outputs = Dense(MAX_LEN, activation=\"softmax\")\n",
    "model = Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
