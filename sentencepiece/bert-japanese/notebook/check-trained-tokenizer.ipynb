{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check trained tokenizer\n",
    "\n",
    "Check trained SentencePiece tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenization_sentencepiece as tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"信じられているから走るのだ。間に合う、間に合わぬは問題でないのだ。\"\n",
    "text2 = \"新たな時代のMarxよこれらの盲目な衝動から動く世界を素晴しく美しい構成に変へよ\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `do_lower_case = True`  case (expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a trained SentencePiece model.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tokenization.FullTokenizer(\n",
    "    model_file=\"../model/wiki-ja.model\",\n",
    "    vocab_file=\"../model/wiki-ja.vocab\",\n",
    "    do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁',\n",
       " '信じられ',\n",
       " 'ている',\n",
       " 'から',\n",
       " '走る',\n",
       " 'のだ',\n",
       " '。',\n",
       " '間に',\n",
       " '合う',\n",
       " '、',\n",
       " '間に合わ',\n",
       " 'ぬ',\n",
       " 'は',\n",
       " '問題',\n",
       " 'でない',\n",
       " 'のだ',\n",
       " '。']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9,\n",
       " 25435,\n",
       " 68,\n",
       " 28,\n",
       " 8956,\n",
       " 6312,\n",
       " 8,\n",
       " 3637,\n",
       " 4277,\n",
       " 7,\n",
       " 23144,\n",
       " 2777,\n",
       " 11,\n",
       " 451,\n",
       " 4772,\n",
       " 6312,\n",
       " 8]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids( tokenizer.tokenize(text1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁',\n",
       " '新たな',\n",
       " '時代の',\n",
       " 'mar',\n",
       " 'x',\n",
       " 'よ',\n",
       " 'これらの',\n",
       " '盲',\n",
       " '目',\n",
       " 'な',\n",
       " '衝動',\n",
       " 'から',\n",
       " '動く',\n",
       " '世界',\n",
       " 'を',\n",
       " '素',\n",
       " '晴',\n",
       " 'しく',\n",
       " '美しい',\n",
       " '構成',\n",
       " 'に',\n",
       " '変',\n",
       " 'へ',\n",
       " 'よ']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9,\n",
       " 1379,\n",
       " 1097,\n",
       " 6459,\n",
       " 282,\n",
       " 842,\n",
       " 1432,\n",
       " 12428,\n",
       " 303,\n",
       " 57,\n",
       " 30802,\n",
       " 28,\n",
       " 11612,\n",
       " 301,\n",
       " 18,\n",
       " 1407,\n",
       " 3606,\n",
       " 3526,\n",
       " 5797,\n",
       " 1171,\n",
       " 17,\n",
       " 1987,\n",
       " 90,\n",
       " 842]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids( tokenizer.tokenize(text2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁',\n",
       " '新たな',\n",
       " '時代の',\n",
       " 'mar',\n",
       " 'x',\n",
       " 'よ',\n",
       " 'これらの',\n",
       " '盲',\n",
       " '目',\n",
       " 'な',\n",
       " '衝動',\n",
       " 'から',\n",
       " '動く',\n",
       " '世界',\n",
       " 'を',\n",
       " '素',\n",
       " '晴',\n",
       " 'しく',\n",
       " '美しい',\n",
       " '構成',\n",
       " 'に',\n",
       " '変',\n",
       " 'へ',\n",
       " 'よ']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens( tokenizer.convert_tokens_to_ids( tokenizer.tokenize(text2) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `do_lower_case = False`  case (Unexpected)\n",
    "\n",
    "Note that English uppercase characters are NOT converted into lowercase ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a trained SentencePiece model.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tokenization.FullTokenizer(\n",
    "    model_file=\"../model/wiki-ja.model\",\n",
    "    vocab_file=\"../model/wiki-ja.vocab\",\n",
    "    do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁',\n",
       " '信じられ',\n",
       " 'ている',\n",
       " 'から',\n",
       " '走る',\n",
       " 'のだ',\n",
       " '。',\n",
       " '間に',\n",
       " '合う',\n",
       " '、',\n",
       " '間に合わ',\n",
       " 'ぬ',\n",
       " 'は',\n",
       " '問題',\n",
       " 'でない',\n",
       " 'のだ',\n",
       " '。']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁',\n",
       " '新たな',\n",
       " '時代の',\n",
       " 'M',\n",
       " 'ar',\n",
       " 'x',\n",
       " 'よ',\n",
       " 'これらの',\n",
       " '盲',\n",
       " '目',\n",
       " 'な',\n",
       " '衝動',\n",
       " 'から',\n",
       " '動く',\n",
       " '世界',\n",
       " 'を',\n",
       " '素',\n",
       " '晴',\n",
       " 'しく',\n",
       " '美しい',\n",
       " '構成',\n",
       " 'に',\n",
       " '変',\n",
       " 'へ',\n",
       " 'よ']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9,\n",
       " 1379,\n",
       " 1097,\n",
       " 0,\n",
       " 2381,\n",
       " 282,\n",
       " 842,\n",
       " 1432,\n",
       " 12428,\n",
       " 303,\n",
       " 57,\n",
       " 30802,\n",
       " 28,\n",
       " 11612,\n",
       " 301,\n",
       " 18,\n",
       " 1407,\n",
       " 3606,\n",
       " 3526,\n",
       " 5797,\n",
       " 1171,\n",
       " 17,\n",
       " 1987,\n",
       " 90,\n",
       " 842]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids( tokenizer.tokenize(text2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁',\n",
       " '新たな',\n",
       " '時代の',\n",
       " '<unk>',\n",
       " 'ar',\n",
       " 'x',\n",
       " 'よ',\n",
       " 'これらの',\n",
       " '盲',\n",
       " '目',\n",
       " 'な',\n",
       " '衝動',\n",
       " 'から',\n",
       " '動く',\n",
       " '世界',\n",
       " 'を',\n",
       " '素',\n",
       " '晴',\n",
       " 'しく',\n",
       " '美しい',\n",
       " '構成',\n",
       " 'に',\n",
       " '変',\n",
       " 'へ',\n",
       " 'よ']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens( tokenizer.convert_tokens_to_ids( tokenizer.tokenize(text2) ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
