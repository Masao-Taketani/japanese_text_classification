{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning of the pretrained Japanese BERT model\n",
    "\n",
    "Finetune the pretrained model to solve multi-class classification problems.  \n",
    "This notebook requires the following objects:\n",
    "- trained sentencepiece model (model and vocab files)\n",
    "- pretrained Japanese BERT model\n",
    "\n",
    "Dataset is livedoor ニュースコーパス in https://www.rondhuit.com/download.html.  \n",
    "We make test:dev:train = 2:2:6 datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "\n",
    "- Full training data\n",
    "  - BERT with SentencePiece\n",
    "    ```\n",
    "                    precision    recall  f1-score   support\n",
    "\n",
    "    dokujo-tsushin       0.98      0.94      0.96       178\n",
    "      it-life-hack       0.96      0.97      0.96       172\n",
    "     kaden-channel       0.99      0.98      0.99       176\n",
    "    livedoor-homme       0.98      0.88      0.93        95\n",
    "       movie-enter       0.96      0.99      0.98       158\n",
    "            peachy       0.94      0.98      0.96       174\n",
    "              smax       0.98      0.99      0.99       167\n",
    "      sports-watch       0.98      1.00      0.99       190\n",
    "        topic-news       0.99      0.98      0.98       163\n",
    "\n",
    "         micro avg       0.97      0.97      0.97      1473\n",
    "         macro avg       0.97      0.97      0.97      1473\n",
    "      weighted avg       0.97      0.97      0.97      1473\n",
    "    ```\n",
    "  - sklearn GradientBoostingClassifier with MeCab\n",
    "    ```\n",
    "                      precision    recall  f1-score   support\n",
    "\n",
    "    dokujo-tsushin       0.89      0.86      0.88       178\n",
    "      it-life-hack       0.91      0.90      0.91       172\n",
    "     kaden-channel       0.90      0.94      0.92       176\n",
    "    livedoor-homme       0.79      0.74      0.76        95\n",
    "       movie-enter       0.93      0.96      0.95       158\n",
    "            peachy       0.87      0.92      0.89       174\n",
    "              smax       0.99      1.00      1.00       167\n",
    "      sports-watch       0.93      0.98      0.96       190\n",
    "        topic-news       0.96      0.86      0.91       163\n",
    "\n",
    "         micro avg       0.92      0.92      0.92      1473\n",
    "         macro avg       0.91      0.91      0.91      1473\n",
    "      weighted avg       0.92      0.92      0.91      1473\n",
    "    ```\n",
    "\n",
    "- Small training data (1/5 of full training data)\n",
    "  - BERT with SentencePiece\n",
    "    ```\n",
    "                    precision    recall  f1-score   support\n",
    "\n",
    "    dokujo-tsushin       0.97      0.87      0.92       178\n",
    "      it-life-hack       0.86      0.86      0.86       172\n",
    "     kaden-channel       0.95      0.94      0.95       176\n",
    "    livedoor-homme       0.82      0.82      0.82        95\n",
    "       movie-enter       0.97      0.99      0.98       158\n",
    "            peachy       0.89      0.95      0.92       174\n",
    "              smax       0.94      0.96      0.95       167\n",
    "      sports-watch       0.97      0.97      0.97       190\n",
    "        topic-news       0.94      0.94      0.94       163\n",
    "\n",
    "         micro avg       0.93      0.93      0.93      1473\n",
    "         macro avg       0.92      0.92      0.92      1473\n",
    "      weighted avg       0.93      0.93      0.93      1473\n",
    "    ```\n",
    "  - sklearn GradientBoostingClassifier with MeCab\n",
    "    ```\n",
    "                    precision    recall  f1-score   support\n",
    "\n",
    "    dokujo-tsushin       0.82      0.71      0.76       178\n",
    "      it-life-hack       0.86      0.88      0.87       172\n",
    "     kaden-channel       0.91      0.87      0.89       176\n",
    "    livedoor-homme       0.67      0.63      0.65        95\n",
    "       movie-enter       0.87      0.95      0.91       158\n",
    "            peachy       0.70      0.78      0.73       174\n",
    "              smax       1.00      1.00      1.00       167\n",
    "      sports-watch       0.87      0.95      0.91       190\n",
    "        topic-news       0.92      0.82      0.87       163\n",
    "\n",
    "         micro avg       0.85      0.85      0.85      1473\n",
    "         macro avg       0.85      0.84      0.84      1473\n",
    "      weighted avg       0.86      0.85      0.85      1473\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data2/m-taketani/practice/text_classification/sentencepiece/bert-japanese/notebook/../config.ini']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import sys\n",
    "import tarfile \n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "CURDIR = os.getcwd()\n",
    "CONFIGPATH = os.path.join(CURDIR, os.pardir, 'config.ini')\n",
    "config = configparser.ConfigParser()\n",
    "config.read(CONFIGPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparing\n",
    "\n",
    "You need execute the following cells just once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILEURL = config['FINETUNING-DATA']['FILEURL']\n",
    "#FILEPATH = config['FINETUNING-DATA']['FILEPATH']\n",
    "#EXTRACTDIR = config['FINETUNING-DATA']['TEXTDIR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = str.maketrans({\n",
    "    '\\n': '',\n",
    "    '\\t': '　',\n",
    "    '\\r': '',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "all_text = []\n",
    "all_label = []\n",
    "\n",
    "for cat in categories:\n",
    "    files = glob.glob(os.path.join(EXTRACTDIR, \"text\", cat, \"{}*.txt\".format(cat)))\n",
    "    files = sorted(files)\n",
    "    body = [ extract_txt(elem).translate(table) for elem in files ]\n",
    "    label = [cat] * len(body)\n",
    "    \n",
    "    all_text.extend(body)\n",
    "    all_label.extend(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'text' : all_text, 'label' : all_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1, random_state=23).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save data as tsv files.  \n",
    "test:dev:train = 2:2:6. To check the usability of finetuning, we also prepare sampled training data (1/5 of full training data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:len(df) // 5].to_csv( os.path.join(EXTRACTDIR, \"test.tsv\"), sep='\\t', index=False)\n",
    "df[len(df) // 5:len(df)*2 // 5].to_csv( os.path.join(EXTRACTDIR, \"dev.tsv\"), sep='\\t', index=False)\n",
    "df[len(df)*2 // 5:].to_csv( os.path.join(EXTRACTDIR, \"train.tsv\"), sep='\\t', index=False)\n",
    "\n",
    "### 1/5 of full training data.\n",
    "# df[:len(df) // 5].to_csv( os.path.join(EXTRACTDIR, \"test.tsv\"), sep='\\t', index=False)\n",
    "# df[len(df) // 5:len(df)*2 // 5].to_csv( os.path.join(EXTRACTDIR, \"dev.tsv\"), sep='\\t', index=False)\n",
    "# df[len(df)*2 // 5:].sample(frac=0.2, random_state=23).to_csv( os.path.join(EXTRACTDIR, \"train.tsv\"), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune pre-trained model\n",
    "\n",
    "It will take a lot of hours to execute the following cells on CPU environment.  \n",
    "You can also use colab to recieve the power of TPU. You need to uplode the created data onto your GCS bucket.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1zZH2GWe0U-7GjJ2w2duodFfEUptvHjcx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_MODEL_PATH = '../model/model.ckpt-1400000'\n",
    "FINETUNE_OUTPUT_DIR = '../model/livedoor_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1005 19:06:04.617552 140609621669632 deprecation_wrapper.py:119] From /data2/m-taketani/practice/text_classification/sentencepiece/bert-japanese/src/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1005 19:06:04.618601 140609621669632 deprecation_wrapper.py:119] From ../src/run_classifier.py:855: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "W1005 19:06:04.619134 140609621669632 deprecation_wrapper.py:119] From ../src/run_classifier.py:660: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "W1005 19:06:04.619275 140609621669632 deprecation_wrapper.py:119] From ../src/run_classifier.py:660: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "W1005 19:06:04.619673 140609621669632 deprecation_wrapper.py:119] From /data2/m-taketani/practice/text_classification/sentencepiece/bert-japanese/src/modeling.py:92: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W1005 19:06:04.620301 140609621669632 deprecation_wrapper.py:119] From ../src/run_classifier.py:681: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "Loaded a trained SentencePiece model.\n",
      "W1005 19:06:05.680080 140609621669632 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W1005 19:06:05.680629 140609621669632 deprecation_wrapper.py:119] From ../src/run_classifier.py:206: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "lines [['text', 'label'], ['「もう仮病使えよ」香川、長友ら招集に  '], ['14日、日本サッカー協会は29日に行なわれるW杯アジア3次予選・ウズベキスタン戦に向けて香川真司(ドルトムント/ドイツ)、長友佑都(インテル/イタリア)ら海外組14人の招集を求め、所属クラブに協力を要請する文書を送付したと発表した。負傷中の本田圭佑(CSKAモスクワ/ロシア)は含まれないものの、所属クラブへの完全移籍が見送られた宇佐美貴史(バイエルン/ドイツ)、移籍したばかりの家長昭博(蔚山現代/韓国)らの名前もあるという。'], [], [' しかし、日本はすでに最終予選進出を決めており、この試合は形としては消化試合となる。海外組を含めたフルメンバーを投入する意図は「試合間隔をあけすぎないこと」などが予想されるが、特に海外で好調を維持する香川、長友の招集にはサッカーファンからさまざまな反応が出た。'], [], [' 「新戦力発掘しないでどうすんだよ」「宇佐美は五輪のほうに呼べよ」「ジーコ解任デモやった奴、出番だぞ」「もう仮病使えよ」「ドルトムントは招集文書破り捨ててOK」といった、海外組の招集に反対する声が高まった一方で、「ここで呼ばなきゃ、6月の最終予選にぶっつけ本番だぞ」「海外組がいるのといないのとじゃスポンサー料が全然違うからな」「いやこれくらいこなせるだろwお前ら過保護w」といった意見も散見された。'], [], ['■関連リンク'], ['・香川真司の得点で勝利。チームも香川も好調を維持。\\u3000【ボルシア・ドルトムントｖｓレヴァークーゼン】']]\n",
      "Traceback (most recent call last):\n",
      "  File \"../src/run_classifier.py\", line 855, in <module>\n",
      "    tf.app.run()\n",
      "  File \"/home/m-taketani/.pyenv/versions/anaconda3-5.2.0/envs/py37/lib/python3.7/site-packages/tensorflow/python/platform/app.py\", line 40, in run\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
      "  File \"/home/m-taketani/.pyenv/versions/anaconda3-5.2.0/envs/py37/lib/python3.7/site-packages/absl/app.py\", line 300, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/home/m-taketani/.pyenv/versions/anaconda3-5.2.0/envs/py37/lib/python3.7/site-packages/absl/app.py\", line 251, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"../src/run_classifier.py\", line 716, in main\n",
      "    train_examples = processor.get_train_examples(FLAGS.data_dir)\n",
      "  File \"../src/run_classifier.py\", line 220, in get_train_examples\n",
      "    self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
      "  File \"../src/run_classifier.py\", line 247, in _create_examples\n",
      "    label = tokenization.convert_to_unicode(line[idx_label])\n",
      "IndexError: list index out of range\n",
      "CPU times: user 68 ms, sys: 28 ms, total: 96 ms\n",
      "Wall time: 4.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# It will take many hours on CPU environment.\n",
    "\n",
    "!python3 ../src/run_classifier.py \\\n",
    "  --task_name=livedoor \\\n",
    "  --do_train=true \\\n",
    "  --do_eval=true \\\n",
    "  --data_dir=../data/livedoor \\\n",
    "  --model_file=../model/wiki-ja.model \\\n",
    "  --vocab_file=../model/wiki-ja.vocab \\\n",
    "  --init_checkpoint={PRETRAINED_MODEL_PATH} \\\n",
    "  --max_seq_length=512 \\\n",
    "  --train_batch_size=4 \\\n",
    "  --learning_rate=2e-5 \\\n",
    "  --num_train_epochs=10 \\\n",
    "  --output_dir={FINETUNE_OUTPUT_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict using the finetuned model\n",
    "\n",
    "Let's predict test data using the finetuned model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import tokenization_sentencepiece as tokenization\n",
    "from run_classifier import LivedoorProcessor\n",
    "from run_classifier import model_fn_builder\n",
    "from run_classifier import file_based_input_fn_builder\n",
    "from run_classifier import file_based_convert_examples_to_features\n",
    "from utils import str_to_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../bert\")\n",
    "\n",
    "import modeling\n",
    "import optimization\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "\n",
    "bert_config_file = tempfile.NamedTemporaryFile(mode='w+t', encoding='utf-8', suffix='.json')\n",
    "bert_config_file.write(json.dumps({k:str_to_value(v) for k,v in config['BERT-CONFIG'].items()}))\n",
    "bert_config_file.seek(0)\n",
    "bert_config = modeling.BertConfig.from_json_file(bert_config_file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ckpts = glob.glob(\"{}/model.ckpt*data*\".format(FINETUNE_OUTPUT_DIR))\n",
    "latest_ckpt = sorted(output_ckpts)[-1]\n",
    "FINETUNED_MODEL_PATH = latest_ckpt.split('.data-00000-of-00001')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FLAGS(object):\n",
    "    '''Parameters.'''\n",
    "    def __init__(self):\n",
    "        self.model_file = \"../model/wiki-ja.model\"\n",
    "        self.vocab_file = \"../model/wiki-ja.vocab\"\n",
    "        self.do_lower_case = True\n",
    "        self.use_tpu = False\n",
    "        self.output_dir = \"/dummy\"\n",
    "        self.data_dir = \"../data/livedoor\"\n",
    "        self.max_seq_length = 512\n",
    "        self.init_checkpoint = FINETUNED_MODEL_PATH\n",
    "        self.predict_batch_size = 4\n",
    "        \n",
    "        # The following parameters are not used in predictions.\n",
    "        # Just use to create RunConfig.\n",
    "        self.master = None\n",
    "        self.save_checkpoints_steps = 1\n",
    "        self.iterations_per_loop = 1\n",
    "        self.num_tpu_cores = 1\n",
    "        self.learning_rate = 0\n",
    "        self.num_warmup_steps = 0\n",
    "        self.num_train_steps = 0\n",
    "        self.train_batch_size = 0\n",
    "        self.eval_batch_size = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = FLAGS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = LivedoorProcessor()\n",
    "label_list = processor.get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenization.FullTokenizer(\n",
    "    model_file=FLAGS.model_file, vocab_file=FLAGS.vocab_file,\n",
    "    do_lower_case=FLAGS.do_lower_case)\n",
    "\n",
    "tpu_cluster_resolver = None\n",
    "\n",
    "is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n",
    "\n",
    "run_config = tf.contrib.tpu.RunConfig(\n",
    "    cluster=tpu_cluster_resolver,\n",
    "    master=FLAGS.master,\n",
    "    model_dir=FLAGS.output_dir,\n",
    "    save_checkpoints_steps=FLAGS.save_checkpoints_steps,\n",
    "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
    "        iterations_per_loop=FLAGS.iterations_per_loop,\n",
    "        num_shards=FLAGS.num_tpu_cores,\n",
    "        per_host_input_for_training=is_per_host))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fn = model_fn_builder(\n",
    "    bert_config=bert_config,\n",
    "    num_labels=len(label_list),\n",
    "    init_checkpoint=FLAGS.init_checkpoint,\n",
    "    learning_rate=FLAGS.learning_rate,\n",
    "    num_train_steps=FLAGS.num_train_steps,\n",
    "    num_warmup_steps=FLAGS.num_warmup_steps,\n",
    "    use_tpu=FLAGS.use_tpu,\n",
    "    use_one_hot_embeddings=FLAGS.use_tpu)\n",
    "\n",
    "\n",
    "estimator = tf.contrib.tpu.TPUEstimator(\n",
    "    use_tpu=FLAGS.use_tpu,\n",
    "    model_fn=model_fn,\n",
    "    config=run_config,\n",
    "    train_batch_size=FLAGS.train_batch_size,\n",
    "    eval_batch_size=FLAGS.eval_batch_size,\n",
    "    predict_batch_size=FLAGS.predict_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_examples = processor.get_test_examples(FLAGS.data_dir)\n",
    "predict_file = tempfile.NamedTemporaryFile(mode='w+t', encoding='utf-8', suffix='.tf_record')\n",
    "\n",
    "file_based_convert_examples_to_features(predict_examples, label_list,\n",
    "                                        FLAGS.max_seq_length, tokenizer,\n",
    "                                        predict_file.name)\n",
    "\n",
    "predict_drop_remainder = True if FLAGS.use_tpu else False\n",
    "\n",
    "predict_input_fn = file_based_input_fn_builder(\n",
    "    input_file=predict_file.name,\n",
    "    seq_length=FLAGS.max_seq_length,\n",
    "    is_training=False,\n",
    "    drop_remainder=predict_drop_remainder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = estimator.predict(input_fn=predict_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# It will take a few hours on CPU environment.\n",
    "\n",
    "result = list(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read test data set and add prediction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"../data/livedoor/test.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['predict'] = [ label_list[elem['probabilities'].argmax()] for elem in result ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum( test_df['label'] == test_df['predict'] ) / len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A littel more detailed check using `sklearn.metrics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_df['label'], test_df['predict']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(test_df['label'], test_df['predict']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/livedoor/train.tsv\", sep='\\t')\n",
    "dev_df = pd.read_csv(\"../data/livedoor/dev.tsv\", sep='\\t')\n",
    "test_df = pd.read_csv(\"../data/livedoor/test.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install -q -y mecab libmecab-dev mecab-ipadic mecab-ipadic-utf8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mecab-python3==0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import MeCab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MeCab.Tagger(\"-Owakati\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dev_df = pd.concat([train_df, dev_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dev_xs = train_dev_df['text'].apply(lambda x: m.parse(x))\n",
    "train_dev_ys = train_dev_df['label']\n",
    "\n",
    "test_xs = test_df['text'].apply(lambda x: m.parse(x))\n",
    "test_ys = test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=750)\n",
    "train_dev_xs_ = vectorizer.fit_transform(train_dev_xs)\n",
    "test_xs_ = vectorizer.transform(test_xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following set up is not exactly identical to that of BERT because inside Classifier it uses `train_test_split` with shuffle.  \n",
    "In addition, parameters are not well tuned, however, we think it's enough to check the power of BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=200,\n",
    "                                   validation_fraction=len(dev_df)/len(train_df),\n",
    "                                   n_iter_no_change=5,\n",
    "                                   tol=0.01,\n",
    "                                   random_state=23)\n",
    "\n",
    "### 1/5 of full training data.\n",
    "# model = GradientBoostingClassifier(n_estimators=200,\n",
    "#                                    validation_fraction=len(dev_df)/len(train_df),\n",
    "#                                    n_iter_no_change=5,\n",
    "#                                    tol=0.01,\n",
    "#                                    random_state=23)\n",
    "\n",
    "model.fit(train_dev_xs_, train_dev_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_ys, model.predict(test_xs_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(test_ys, model.predict(test_xs_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ../../preprocess_data_for_transformer_with_sp.ipynb ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
